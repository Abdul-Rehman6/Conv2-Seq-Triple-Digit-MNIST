# Encoderâ€‘Decoder CNNâ€‘LSTM Network for MNIST Triplet Classification

This repository contains an **Encoderâ€‘Decoder** model implemented in **PyTorch**, combining a **CNN encoder** and an **LSTM decoder**, trained on a **triplet version of the MNIST dataset**.  
Instead of simple digit classification, the model processes sets of three MNIST images at once (triplets) to learn richer sequence relationships. This was developed as part of a technical interview task.

---

## ğŸ“ Repository Structure

```text
encoder-decoder-triplet-mnist/
â”‚
â”œâ”€â”€ Encoder_Decoder_Network.ipynb   â† Jupyter Notebook: data loading, model definition, training loop, evaluation, plots
â”œâ”€â”€ best_model.pth                  â† Saved bestâ€‘validationâ€‘loss model weights (PyTorch state_dict)
â”œâ”€â”€ requirements.txt                â† Python dependencies
â”œâ”€â”€ .gitignore                      â† Untracked files (cache, checkpoints, env, etc.)
â”œâ”€â”€ README.md                       â† This file

---

## ğŸ§  Model Architecture Overview

The Encoder-Decoder model follows this basic structure:

- **Encoder**: Takes an input sequence and encodes it into a fixed-size context vector using LSTM.
- **Decoder**: Receives the context vector and generates the output sequence token by token using another LSTM.

```text
Input Text â†’ [Encoder LSTM] â†’ Context Vector â†’ [Decoder LSTM] â†’ Output Text
